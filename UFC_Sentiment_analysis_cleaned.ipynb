{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8IXilEtvKt_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, classification_report, r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = \"/content/ufc_comments.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "BmrqflxgvgG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure required columns exist\n",
        "required_columns = {'Comment', 'Sentiment'}\n",
        "if not required_columns.issubset(df.columns):\n",
        "    print(\"Error: Required columns not found in dataset\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "mQ_7OsYxvgKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df = df[['Comment', 'Sentiment']].dropna()\n",
        "\n",
        "# Convert labels to numerical format\n",
        "sentiment_mapping = {'Positive': 1, 'Negative': 0, 'Neutral': 2}\n",
        "df['Sentiment_Label'] = df['Sentiment'].map(sentiment_mapping)"
      ],
      "metadata": {
        "id": "5RZqxNTdvgNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for invalid labels\n",
        "if df['Sentiment_Label'].isnull().any():\n",
        "    print(\"Error: Dataset contains invalid sentiment labels\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "PQ-nz7rzvgQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokens = tokenizer(df[\"Comment\"].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "73d5f116b39444229eea53dd86a53f10",
            "9c62812ca7a8402684d714560bbd2daa",
            "bf660d2c75954a568bd58115fc76e827",
            "23279c325bc94bb09e903f21d034bb4b",
            "6ebc868c97bc4e70a6a6e80fcc31c0f4",
            "402aa47c20ad440fad61372d25f670af",
            "e6988f3541d2407db44e23a134523e8b",
            "7e0462a29b1a457998c15c57efb50910",
            "b1e4ba6d14c6491ca61fc16753c03a33",
            "336fca92e445423eb1fa23fb468d6af2",
            "e2f7d3f732094e40a3e427b9ecbdcf60",
            "8c7dd0bf13be442d999fdf5e6005f169",
            "a6b95507fbf8475188c2c07c36bd246d",
            "d4646ebc576648acb0d9e221f96ead57",
            "cc39c098a51c49308fec6bffc8779fd7",
            "ddbe0d557f7f431cafe09a5d7ce50371",
            "786968c07c3a46aeb8eb066ca2b814c2",
            "24657169b424470f895ee6d9511d2e0f",
            "3517dcaa7c78455a81a6d9f9a4a4ef6d",
            "b8bd8a863282493abf2f93308f430468",
            "a8c04a38285e47d48cc900f12ac942e8",
            "99f6e024d06d49868d57d22597d3dfb8",
            "3ddd2b92768a4011b9f9c6c1bc7ad648",
            "868496836a0a4937bb3e4ea919ac30be",
            "88b04f7ce32b4edd9a227f6bd3e4cf44",
            "2194971131744ac88a794058bc532ece",
            "557619689d0f4c08a1d8f7a1c9040c7f",
            "c51f3cdf2d2944b5b4a07395e06a85c6",
            "6267acfee60043208643437f91e32dae",
            "cac3570184e44c6496b5d7b429a6c8dd",
            "8e4476da3f6f48e9810ce74d761f7221",
            "20099bea89574093aa336c4b4d66625a",
            "2c5d62abdaf64d4e98b697c0060aa91d",
            "cbbe43c40d5c431c865d69cc81d8eca7",
            "32a3563238bc4bb68b0d44d13efee802",
            "72a417c21afb4dfabb469737ef6fc9aa",
            "2a914d3b6a7f4f169c41b6a53fed1f4d",
            "9225c38395bc457e9a59ebffe0902204",
            "5a1f820b6b94443391ff83a3846012af",
            "a9fdc3a68e14492c8ab5f1a38f536d9d",
            "e04bbb750b7d40ad80efc9e133b97af8",
            "8527c9bf423c4b8aae20b9d4167e6b4a",
            "b0fe88c6845846f59fd67bdb8aba1cee",
            "6dec1fa49629493e8eef7271894f308e"
          ]
        },
        "id": "YjAn2nBuvgS8",
        "outputId": "72634011-cd81-4201-c57d-d8a6e4bd39bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tokens['input_ids'], df['Sentiment_Label'].values, test_size=0.2, random_state=42)\n",
        "train_data = list(zip(X_train, y_train))\n",
        "test_data = list(zip(X_test, y_test))"
      ],
      "metadata": {
        "id": "73EhK3wqvgV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset Class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx][0], torch.tensor(self.data[idx][1], dtype=torch.long)\n",
        "\n",
        "train_loader = DataLoader(SentimentDataset(train_data), batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(SentimentDataset(test_data), batch_size=16)\n"
      ],
      "metadata": {
        "id": "BZF9RV50vgY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT Model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919,
          "referenced_widgets": [
            "5a737ed423dd44e389b60cedd9c246cf",
            "7c97e35b9fac4c149c89e5cc92cb9e97",
            "f05a4daaf70447579b04a1dc5871923a",
            "e9f724cd5bb0490c93e6f273d94402d2",
            "ee40d85f07f44a4190b600669e5c16bf",
            "9ceec03194334f3992477468bce285af",
            "9fb34bb9cfd143a292821116cee2b925",
            "f06c2ed4a027477e87576259444bdef3",
            "ae64f136f1554687a9d47fb97a38199a",
            "c8a6d1e27b02463bb9ed5da2480dd099",
            "30904dc16c284502bf8b3ce4033ef209"
          ]
        },
        "id": "apjV86hlvgbs",
        "outputId": "82da574d-ded9-4604-a7db-69b1485e67c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Update for 5 epochs\n",
        "num_training_steps = len(train_loader) * 5  # 5 epochs\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Mixed Precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Improved Training Loop for 5 epochs\n",
        "def train_model(model, train_loader, epochs=5, accumulation_steps=2):  # 5 epochs\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct, total = 0, 0  # Track accuracy\n",
        "\n",
        "        for step, batch in enumerate(train_loader):\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs, labels=labels)\n",
        "                loss = outputs.loss / accumulation_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_loader):\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                lr_scheduler.step()\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = correct / total * 100\n",
        "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
        "\n",
        "# Run optimized training\n",
        "train_model(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vugCxPOGvgea",
        "outputId": "68846cac-e091-4abf-9b7f-fc0fd0950003"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Updated Evaluation Function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.argmax(F.softmax(outputs.logits, dim=1), dim=1)\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
        "    r2 = r2_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=['Negative', 'Positive', 'Neutral'])\n",
        "\n",
        "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"R\u00b2 Score: {r2:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive', 'Neutral'],\n",
        "                yticklabels=['Negative', 'Positive', 'Neutral'])\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the updated function\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "VIQQgzSuvgh9",
        "outputId": "199c9d38-55f6-45a2-adfe-03861376d628"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment for new comments\n",
        "def predict_sentiment(model, comments):\n",
        "    model.eval()\n",
        "    tokens = tokenizer(comments, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens['input_ids'])\n",
        "        predictions = torch.argmax(F.softmax(outputs.logits, dim=1), dim=1).cpu().numpy()\n",
        "    sentiment_labels = {0: 'Negative', 1: 'Positive', 2: 'Neutral'}\n",
        "    return [sentiment_labels[pred] for pred in predictions]"
      ],
      "metadata": {
        "id": "SICl9Fz7xW8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example predictions\n",
        "new_comments = [\n",
        "    \"This fight good !\"\n",
        "\n",
        "  ]\n",
        "predictions = predict_sentiment(model, new_comments)\n",
        "for comment, sentiment in zip(new_comments, predictions):\n",
        "    print(f\"Comment: {comment} => Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsimhqo4xXMD",
        "outputId": "7f3674fe-ff23-42a5-ef5a-88fcfbbb20b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --ClearMetadataPreprocessor.enabled=True --clear-output --inplace UFC_sentiment_analysis_.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxSxn0dLxoku",
        "outputId": "1c5a7a43-7bb0-45fb-869b-33c68b1ba109"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}